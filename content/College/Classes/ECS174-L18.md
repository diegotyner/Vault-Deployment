---
created:
  - " 11-26-2024 13:57"
tags:
  - Classes
aliases:
---

# 📗 -> Lecture Date: Name
---
[Slides](https://cs231n.stanford.edu/slides/2022/lecture_9_jiajun.pdf)


## 🎤 Vocab



## ❗ Unit and Larger Context
Finishing the long lecture slide on Object detection

Moving on to GANs



## ✒️ -> Scratch Notes
### 3D Object Detection: 
#### Monocular Camera
Candidate Sampling in 3D space
| (projection)
2D Candiate Boxes
| 
Faster R-CNN
| (Scoring & NMS)
Proposals

- Same idea as faster RCNN, but proposals are in 3D
- 3D bounding box proposal, regress 3D box parameters + class score


#### LIDAR 
Another form of 3D estimation, shoots out beams of lights and seems how long it takes for them to come back. Used to estimate depth. Self driving taxis sometime use them (the big spinning thing on WAYMO cars)

#### Mesh R-CNN
Input Image -> 2D Recognition -> 3D Meshes -> 3D Vocels


### GANs
**Generative Adversarial Networks (GAN)** 
[Example in action](https://thispersondoesnotexist.com/)
- Samples a low dimensional vector (100D) that have characteristics about images. Feeds these into the GAN
#### Generating Random Images
Truly random will return something similar to static. 
- How can we randomly sample from a low dimensional space to create an image in high dimensional space? (10,000 pixels for example)
- How can we get a realistic picture? Only small pockets of "realistic images" in this 10,000D space
![[Latent-Space-Manifold.png|400]]
- Analogous to sampling 3D space and randomly landing on the manifold
> Given any point on the latent space, GAN has to map onto the Data Space on a point which looks natural. Projecting from latent space onto the manifold. 


![[GAN-Architecture.png|600]]
- No matter what the noise is, the generator will always create a realistic looking image.
- The discriminator is a binary classifier: real or fake.
#### Loss
- ~~The *discriminator* wants to *minimize* the loss using gradient descent~~
- ~~The *generator* want to *maximize* the loss using gradient ascent ~~
Subset of parameters we want the minima for, but for another subset we want the maxima
NOT trying to maximize loss, trying to find a saddle point for G and D. We want them both to get better progressively. 
##### Saddle Point:
- Has the property where in one direction is the maxima, and in the other is the minima
Optimizing GANs has very difficult math associated with it, due to the problems we identified

## 🔗 -> Links
### Resources
- Put useful links here


### Connections
- Link all related words
